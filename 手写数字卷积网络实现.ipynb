{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积实现手写数字体识别\n",
    "- 本demo主要通过卷积的方式实现\n",
    "- 本demo没有使用keras等高层api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.库及函数准备\n",
    "- 导入相关package tf\n",
    "- 定义了2个函数，weight_variable/bias_variable，分别用来后续初始化w，b\n",
    "- 定义了2个函数，conv2d/max_pool_2x2，分别用来做卷积和池化\n",
    "- 本demo会话开启，使用的是交互式的`sess = tf.InteractiveSession()`,请注意这种方式的使用语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-4968d53b1a69>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\MNIST\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data\\MNIST\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data\\MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ellen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf \n",
    "\n",
    "#导入数据，创建一个session对象　，之后的运算都会跑在这个session里\n",
    "mnist = input_data.read_data_sets(\"data/MNIST/\",one_hot=True)\n",
    "sess = tf.InteractiveSession()     #交互式的session可以在里面写计算图\n",
    "\n",
    "#定义一个函数，用于初始化所有的权值 W,这里我们给权重添加了一个截断的正态分布噪声　标准差为0.1\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#定义一个函数，用于初始化所有的偏置项 b，这里给偏置加了一个正值0.1来避免死亡节点\n",
    "def bias_variable(shape):\n",
    "    inital = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(inital)\n",
    "\n",
    "#定义一个函数，用于构建卷积层，这里strides都是１　代表不遗漏的划过图像的每一个点\n",
    "def conv2d(x,w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='SAME')      #表示输出与输入图的大小保持不变\n",
    "\n",
    "#定义一个函数，用于构建池化层\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义计算图的输入部分\n",
    "- 本例中用到了`tf.placeholder()`占位符，占位符使用时，请注意参数中的`dtype`必须指定\n",
    "- 下面的代码将11 feed 给 a\n",
    "```python\n",
    "tf.placeholder(dtype, shape=None, name=None)\n",
    "a = tf.placeholder(shape=[],dtype=tf.int32,name='a') #必须指定的是dtype\n",
    "print(a)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a,feed_dict={a:11}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#placceholder 基本都是用于占位符　后面用到先定义\n",
    "\n",
    "#将数据reshape成适合的维度来进行后续的计算\n",
    "x = tf.placeholder(tf.float32,[None,784])#\n",
    "y_ = tf.placeholder(tf.float32,[None,10])\n",
    "x_image = tf.reshape(x,[-1,28,28,1]) #其中的-1表示“目前不确定”，所以在运行的时候程序先考虑后面的28,28和1\n",
    "print(x_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 网络定义\n",
    "- 注意w，b的参数维度设置\n",
    "- 注意激活的位置\n",
    "- 注意softmax的位置\n",
    "- 简单推导下所需要的参数数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-6-2d48dbf976e0>:24: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "#第一个卷积层的定义\n",
    "#Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "#and a filter / kernel tensor of shape\n",
    "#`[filter_height, filter_width, in_channels, out_channels]\n",
    "W_conv1 = weight_variable([5,5,1,32])  #参数是shape                              \n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)               #卷积计算，激活函数为relu\n",
    "h_pool1 = max_pool_2x2(h_conv1)                           #参数是池化的对象\n",
    "\n",
    "#第二个卷积层的定义\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#第一个全连接层的定义\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])   #压平，展开\n",
    "W_fc1 = weight_variable([7*7*64,1024])   #全连接层输入x输出个权重\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1) + b_fc1)\n",
    "\n",
    "#将第一个全连接层　进行dropout　随机丢掉一些神经元不参与运算\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)  #丢掉一些神经元\n",
    "\n",
    "#第二个全连接层　分为十类数据　softmax后输出概率最大的数字\n",
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv),reduction_indices=[1]))        #交叉熵\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)             #这里用Ａdam优化器优化　也可以使用随机梯度下降\n",
    "\n",
    "correct_predition = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predition,tf.float32))                                #准确率\n",
    "\n",
    "tf.initialize_all_variables().run()  \n",
    "#sess.run(tf.initialize_all_variables())#使用全局参数初始化器　并调用run方法　来进行参数初始化\n",
    "\n",
    "tf.summary.scalar('accuracy',accuracy)## 将accuracy的结果写入tensorboard可视化工具\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(\"data/MNIST/board\",sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.开始训练并用测试集测试精度\n",
    "- 再次注意当使用`sess = tf.InteractiveSession()`时，开启计算会话的方式,下面俩种都可以\n",
    "   - `train_accuracy = accuracy.eval(feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0})`\n",
    "   - `train_accuracy = sess.run(accuracy,feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0,training accuracy 0.1\n",
      "step 100,training accuracy 0.7\n",
      "step 200,training accuracy 0.88\n",
      "step 300,training accuracy 0.98\n",
      "step 400,training accuracy 0.92\n",
      "step 500,training accuracy 0.96\n",
      "step 600,training accuracy 0.94\n",
      "step 700,training accuracy 0.94\n",
      "step 800,training accuracy 0.88\n",
      "step 900,training accuracy 0.98\n",
      "test accuracy 0.9599\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0})        #每一百次打印一下准确率\n",
    "        print(\"step %d,training accuracy %g\"%(i,train_accuracy))\n",
    "        train_summary = sess.run(merged, feed_dict={x:batch[0],y_:batch[1],keep_prob:1.0})\n",
    "        train_writer.add_summary(train_summary,i)\n",
    "\n",
    "    train_step.run(feed_dict={x:batch[0],y_:batch[1],keep_prob:0.5})          #train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)  \n",
    "    #sess.run(xxxxxxxxxxx)\n",
    "\n",
    "print (\"test accuracy %g\"%accuracy.eval(feed_dict={x:mnist.test.images[:50],y_:mnist.test.labels[:50],keep_prob:1.0}))    #开始测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 使用自己手写的图片验证\n",
    "- 此例同demo01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "(28, 28, 3)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_label(label_num):\n",
    "    label = np.zeros((1, 10),dtype='float32')\n",
    "    label[:,label_num] = 1.0\n",
    "    print(label)\n",
    "    return label\n",
    "\n",
    "label_test = make_label(4)\n",
    "# 图片路径\n",
    "img_path = \"data/MNIST_test/4.png\"\n",
    "img_file = cv2.imread(img_path)\n",
    "print(img_file.shape)\n",
    "img_file = cv2.cvtColor(img_file, cv2.COLOR_RGB2GRAY)\n",
    "print(img_file.shape)\n",
    "img_file = 255 - img_file\n",
    "for row in range(img_file.shape[0]):\n",
    "    for col in range(img_file.shape[1]):\n",
    "        if img_file[row][col] < 120.0:\n",
    "            img_file[row][col] = 0\n",
    "plt.imshow(img_file,'gray')\n",
    "plt.show()\n",
    "data_test = img_file / 255\n",
    "data_test.shape\n",
    "data_test = np.float32(img_file.reshape(1, 28*28))\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 1\n"
     ]
    }
   ],
   "source": [
    "print (\"test accuracy %g\"%accuracy.eval(feed_dict={x:data_test, y_:label_test, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
